Rationale against other methods

In evaluating the inter-rater reliability of our study, we considered several statistical measures but ultimately chose percent agreement due to the unique characteristics of our data and the specific requirements of our analysis. While methods such as Cohen’s Kappa, Fleiss' Kappa, Gwet's AC1, Intraclass Correlation Coefficient (ICC), and Krippendorff’s Alpha are widely used for assessing the reliability of raters, these approaches were not deemed suitable for our study for the following reasons: 

1. Cohen’s Kappa and Fleiss' Kappa: These kappa statistics are designed to account for chance agreement in datasets with nominal data. However, our dataset exhibited an exceptionally high level of agreement (99.1% across 109 out of 110 cases), which could lead to paradoxical results with kappa statistics. Specifically, kappa values can be misleadingly low in situations of the high agreement due to the kappa paradox, where the observed agreement is almost perfect, and the expected agreement by chance is also high. (Fleiss' Kappa (~0.49)

2. Gwet's AC1: Although Gwet's AC1 is less sensitive to the prevalence problem and can be more stable in cases of high agreement, our decision to use percent agreement was based on its simplicity and direct interpretation. Given the near-unanimous consensus among our raters, it still presented an issue. (~0.45)

3. Intraclass Correlation Coefficient (ICC): Typically applied to continuous data, ICC assesses the consistency or conformity of measurements made by multiple observers measuring the same subjects. Our binary (correct/incorrect) dataset did not fit the typical application scenarios for ICC, making it less relevant for our analysis. (regardless of ICC formula incorrect outputs)

4. Krippendorff’s Alpha: Although highly versatile and capable of handling various data types, Krippendorff’s Alpha was considered more complex than needed and beyond my current level of coding, also, since it was a binary rating system and exhibited very high agreement, not needed. (~0.002)

Very Respectfully, 

Wayne A. Ayers-Creech
